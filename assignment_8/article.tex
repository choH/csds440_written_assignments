\documentclass[12pt]{article}
\usepackage{times}
\usepackage{setspace}
\setstretch{1.5}
\usepackage{amsmath,amssymb, amsthm}
\usepackage{graphicx}
\usepackage{bm}
\usepackage[hang, flushmargin]{footmisc}
\usepackage[colorlinks=true]{hyperref}
\usepackage[nameinlink]{cleveref}
\usepackage{footnotebackref}
\usepackage{url}
\usepackage{listings}
\usepackage[most]{tcolorbox}
\usepackage{inconsolata}
\usepackage[papersize={8.5in,11in}, margin=1in]{geometry}
\usepackage{float}
\usepackage{caption}
\usepackage{esint}
\usepackage{url}
\usepackage{enumitem}
\usepackage{subfig}
\usepackage{wasysym}
\newcommand{\ilcode}{\texttt}
\newcommand{\p}{\partial}
\newcommand{\vphi}{\varphi}
\usepackage{etoolbox}
\usepackage{physics}
\usepackage{xcolor}
\patchcmd{\thebibliography}{\section*{\refname}}{}{}{}



\makeatletter
\renewcommand{\@seccntformat}[1]{}
\makeatother

\begin{document}



\title{\textbf{CSDS 440: Assignment 8}}

\author{Shaochen (Henry) ZHONG, \ilcode{sxz517} \\ Mingyang TIE, \ilcode{mxt497}}
\date{Due and submitted on 10/30/2020 \\ Fall 2020, Dr. Ray}
\maketitle


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Problem 33}

The decision surface boundary is defined as $wx + b = 0$. When we modify two constants $c1$ and $c2$ that define the plus plane as $wx + b = c1$ where $c1 > 0$ and the minus plane as $wx + b = c2$ where $c2 < 0$.


When $|c1| \neq |c2|$, the decision surface will be closer to either the plus or minus planes. If $|c1| > |c2|$, the decision surface boundary is closer to minus planes, because when $|c1| > |c2|$, $c1 + c2 > 0$, so $wx + b > 0$. If $|c1| < |c2|$, we can know $c1 + c2 < 0$, therefore the decision surface boundary is closer to plus planes, because $wx + b < 0$. If $|c1| = |c2|$, $wx + b = 0$, it means the resulting decision surface is halfway between plus and minus plane, which is the general SVM case. \newline

When choosing the decision surface boundary, the preference it is really depending on the dataset we have or the task we are doing. For example, if the distribution of the dataset we choose show that the negative class has less predictable data, we need to let the decision surface boundary to be closer the plus plane so that more ``redundency'' is left for negative-labeled outputs.

However, if the purposed task is to identify fire in building, a decision boundary which is closer to minus plane will be preferred as it more examples will be classifed as positive -- which is a preferred bias in this task as the cost of having a couple more false positive is much more tolerable than having more false negative.

If the task and dataset is generally neutral, then we may always redefine the decision boundary to be $wx + b = \frac{1}{2}(c_1 + c_2)$ to have an equal distance toward both the plus and minus plane.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Problem 34}

With $wx +b = 0$, we know that $w$ is perpendicular decision plane as we may select two points on $w$, we have $w(u - v) = wu - wv = -b -(-b) = 0$. Known that the plus and minus plane are parallel to the decision plane, $w$ is perpendicular to both the plus and minus plane.

Say we have $x^+$ on plus plane, let $x^-$ to be a point on minus plane with shortest distance to $x^+$. We know that there must be $x^+ - x^- = \lambda w$ since the shortest distance between two paralleled planes are on their norm. Thus, we have:

\begin{align*}
    1 &= w(x^- + \lambda w) + b \\
    &= wx^- + \lambda w \cdot w + b \\
    \lambda ||w||^2 &= 2
\end{align*}

Since we know the margin is defined as $M = \lambda||w||$, we have $M = \frac{2}{||w||}$ which is independent of $b$.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Problem 35}
% According to the definition we can get such equation:the 95% confidence
% intervals can be expressed:\newline
% $[(e_{A} - 1.96 * \sigma_{A}), (e_{A} + 1.96 * \sigma_{A}) ]$\newline
% in the expression ,we can find these definitons :\newline
% $e_{A}$: means the average of all samples, which can be calculate by $\frac{n_{1} + n_{2} + n_{3} + ... + n_{k}}{k}$, where $n_{k}$ means a sample.\newline
% $\sigma_{A}$: means the standard devation of the samples, which can be calculate by $\sqrt{\frac{e_{A}(1 - e_{A})}{k}}$ where $k$ is the the total number of samples, $e_{A}$ is the average of all samples.\newline
% So according to the problem we should find enough big samples to sure the equation: $e_{A} - e_{B} = 0.1$ is proven ,we can get the inequality is true:\newline
% $(e_{A} - 1.96 * \sigma_{A}) > (e_{B} + 1.96 * \sigma_{B})$\newline
% So we can change the inequality:\newline
% 		\begin{align*}
% 			(e_{A} - 1.96 * \sigma_{A}) > (e_{B} + 1.96 * \sigma_{B}) &= 1.96(\sigma_{B} - \sigma_{A}) < e_{A} - e_{B} \\
% 			&= 1.96(\sqrt{\frac{e_{B}(1 - e_{B})}{k}}+ \sqrt{\frac{e_{A}(1 - e_{A})}{k}}) < e_{A} - e_{B} \\
% 		\end{align*}
% by the transformation we can get the relationship between $(e_{A} , e_{B} )$ and $k$:\newline
% $k > (1.96(\sqrt{e_{B}(1 - e_{B})} + \sqrt{e_{A}(1 - e_{A})}))^2$\newline
% so according to the result ,we can think if the relationship between $(e_{A},e_{B})$ and $k$ is true, difference in error rates of $A$ and $B$ at the $95\%$ confidence level can be
% proven.


We denotes $F = e_A - e_B$ to represent the difference between the error rate of the two classifers. We know that $E(F) = e_1 - e_B$ and the variance will be $V(F) = \frac{e_A(1-e_A) + e_B(1-e_B)}{n}$ according to the property of binomial distribution.

As we may model our calculation as a Gaussian distribution, a $95\%$ CI is around $1.96 \sigma$. We want to make 0 will not in this interval, thus $0.1 -1.96 \sigma> 0 \Longrightarrow 0.1 > 1.96 \sigma$. Now by substitute the $V(F)$ in, we have:

\begin{align*}
    0.1 &> 1.96 \frac{e_A(1-e_A) + e_B(1-e_B)}{n} \\
    &> 1.96 \frac{\sqrt{e_A(1-e_A) + e_B(1-e_B)}}{\sqrt{n}} \\
    \sqrt{n} &> \frac{1.96}{0.1} \sqrt{e_A(1-e_A) + e_B(1-e_B)} \\
    \Longrightarrow n &> 384.16 (e_A(1-e_A) + e_B(1-e_B))
\end{align*}




% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Problem 36}

%
% According to the problem ,we can easily assume Professors Bob‘s experiment result is $[ x1 , x2 ]$ with C\% confidence intervals after N times independent experiment. As the same, we can get Professors Nan’s experiment result is $[ x3 , x4 ]$ with C\% confidence intervals after N times independent experiment. So based on the relationships . According to the definition of confidence intervals:\newline
% $[(e_{A} - k * \sigma_{A}), (e_{A} + k * \sigma_{A}) ]$ where $k$ is changed by the C\% confidence.\newline
% So we can easily get the following two Professors total times with error experiment results:\newline
% Professors Bob: $E1: N * 0.5(x1 + x2)$ and Professors Nan: $E2: N * 0.5(x3 + x4)$\newline
% Based on the independent experiment ,we can add the different experiment results to replace the new experiment results, we can think the Professor Scoop’s experiment results are:\newline
% Total times experiment results: $2N$\newline
% Total times with error experiment results: $E1 + E2$\newline
% Based on this results we can calculate the results of Professor Scoop:\newline
% $e = (E1 + E2) / 2N$ and $\sigma^2 = e(1 - e) / 2N$ and $\sigma = \sqrt{e(1 - e) / 2N}$\newline
% So with the C\% confidence, the confidence interval can be expressed:\newline
% $[(e - k\sigma), (e+k\sigma)]$\newline
% Therefore $[(e - k\sigma), (e+k\sigma)]$ is the best confidence interval that Professor Scoop could report that would be consistent with Profs. Bob and Nan’s findings.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

% \section{References}
% \nocite{*}
% \raggedright
% \bibliography{references.bib}
% \bibliographystyle{plain}

Known that the $95 \%$ CI are $[x_B, y_B]$ and $[x_N, y_N]$ respectively for two datasets, we may deduce the error rates to be $e_B = \frac{x_B + y_B}{2}$ and $e_N = \frac{x_N + y_N}{2}$ for their respective dataset.

Assume Prof. Bob's dataset has $n_B$ examples and Prof. Nan has $n_N$ examples, Prof. Scoop may simply derive his version of error rate to be a combination of the both, which is $e_S = \frac{n_B e_B + n_N e_N}{n_B + n_N}$. This implies $n_S = n_B + n_N$, we may get this $n_S$ (and also $n_B, n_N$) by doing:

\begin{align*}
    x_B &= e_B - 2\sigma_B \\
    2\sqrt{\frac{e_B(1-e_B)}{n_B}} &= e_B - x_B \\
    \frac{4 e_B(1-e_B)}{n_B} &= (e_B - x_B)^2 \\
    \Longrightarrow n_B &= \frac{4 e_B(1-e_B)}{(e_B - x_B)^2} \\
    \text{By doing the same calculation for} \ &n_N \ \text{we have:} \\
    n_N &= \frac{4 e_N(1-e_N)}{(e_N - x_N)^2} \\
    \Longrightarrow n_S &= \frac{4 e_B(1-e_B)}{(e_B - x_B)^2} + \frac{4 e_N(1-e_N)}{(e_N - x_N)^2}
\end{align*}

Since $e_B, n_B, e_N, n_N, n_S$ are now all known, we can calculate $e_S$ accordingly. Now, assume Prof. Scoop will land with a $95 \%$ CI of $[x_S, y_S]$, then there must be:

\begin{align*}
    x_S &= e_S - 2 \sigma_S \\
    &= e_S - 2\sqrt{\frac{e_S(1-e_S)}{n_S}} \\
    y_S &= e_S + 2 \sigma_S \\
    &= e_S + 2\sqrt{\frac{e_S(1-e_S)}{n_S}}
\end{align*}

The above two equations suggest we may derive $x_S$ and $y_S$ with just $e_S$ and $n_S$, which are two known value to us and also to Prof. Scoop. So Prof. Scoop -- while not doing any experiment -- may derive his $95\%$ CI base on Prof. Bob and Prof. Nan's results at the cost of his academic integrity.






\end{document}